{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-28T15:30:48.615609Z",
     "iopub.status.busy": "2025-06-28T15:30:48.615264Z",
     "iopub.status.idle": "2025-06-28T15:30:50.647558Z",
     "shell.execute_reply": "2025-06-28T15:30:50.646180Z",
     "shell.execute_reply.started": "2025-06-28T15:30:48.615579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T15:31:35.466678Z",
     "iopub.status.busy": "2025-06-28T15:31:35.466520Z",
     "iopub.status.idle": "2025-06-28T15:32:02.657172Z",
     "shell.execute_reply": "2025-06-28T15:32:02.656565Z",
     "shell.execute_reply.started": "2025-06-28T15:31:35.466663Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 15:31:51.051452: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751124711.251832      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751124711.318388      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    ElectraTokenizerFast,\n",
    "    ElectraModel,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T15:32:09.119118Z",
     "iopub.status.busy": "2025-06-28T15:32:09.118370Z",
     "iopub.status.idle": "2025-06-28T15:32:09.125402Z",
     "shell.execute_reply": "2025-06-28T15:32:09.124766Z",
     "shell.execute_reply.started": "2025-06-28T15:32:09.119093Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class ArabicTextDataset(Dataset):\n",
    "    \"\"\"Custom dataset for Arabic text multi-task classification\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, emotions, offensive, hate, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.emotions = emotions\n",
    "        self.offensive = offensive\n",
    "        self.hate = hate\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'emotion': torch.tensor(self.emotions[idx], dtype=torch.long),\n",
    "            'offensive': torch.tensor(self.offensive[idx], dtype=torch.long),\n",
    "            'hate': torch.tensor(self.hate[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"Dataset class defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T15:32:21.674678Z",
     "iopub.status.busy": "2025-06-28T15:32:21.674019Z",
     "iopub.status.idle": "2025-06-28T15:32:21.681393Z",
     "shell.execute_reply": "2025-06-28T15:32:21.680580Z",
     "shell.execute_reply.started": "2025-06-28T15:32:21.674655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-task AraELECTRA model class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class MultiTaskAraELECTRA(nn.Module):\n",
    "    \"\"\"Multi-task classification model using Araberta\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, num_emotions, num_offensive, num_hate, dropout=0.3):\n",
    "        super(MultiTaskAraELECTRA, self).__init__()\n",
    "        \n",
    "        # Load pre-trained AraELECTRA model\n",
    "        self.electra = ElectraModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Classification heads for each task\n",
    "        hidden_size = self.electra.config.hidden_size\n",
    "        \n",
    "        self.emotion_classifier = nn.Linear(hidden_size, num_emotions)\n",
    "        self.offensive_classifier = nn.Linear(hidden_size, num_offensive)\n",
    "        self.hate_classifier = nn.Linear(hidden_size, num_hate)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get ELECTRA outputs\n",
    "        outputs = self.electra(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use last hidden state and apply mean pooling\n",
    "        # ELECTRA doesn't have pooler_output, so we use mean pooling\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        \n",
    "        # Mean pooling over sequence length\n",
    "        pooled_output = torch.mean(last_hidden_state, dim=1)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Get predictions for each task\n",
    "        emotion_logits = self.emotion_classifier(pooled_output)\n",
    "        offensive_logits = self.offensive_classifier(pooled_output)\n",
    "        hate_logits = self.hate_classifier(pooled_output)\n",
    "        \n",
    "        return emotion_logits, offensive_logits, hate_logits\n",
    "\n",
    "print(\"Multi-task AraELECTRA model class defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T15:32:34.405615Z",
     "iopub.status.busy": "2025-06-28T15:32:34.405290Z",
     "iopub.status.idle": "2025-06-28T15:32:34.423167Z",
     "shell.execute_reply": "2025-06-28T15:32:34.422309Z",
     "shell.execute_reply.started": "2025-06-28T15:32:34.405591Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main classifier class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class ArabicMultiTaskClassifier:\n",
    "    \"\"\"Main classifier class for Arabic multi-task text classification\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='aubmindlab/bert-base-arabertv2', max_length=512):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Initialize tokenizer - use ElectraTokenizer for AraELECTRA\n",
    "        self.tokenizer = ElectraTokenizerFast.from_pretrained(model_name)\n",
    "        \n",
    "        # Label encoders for each task\n",
    "        self.emotion_encoder = LabelEncoder()\n",
    "        self.offensive_encoder = LabelEncoder()\n",
    "        self.hate_encoder = LabelEncoder()\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"Load and preprocess data from Excel or CSV file\"\"\"\n",
    "        print(\"Loading data...\")\n",
    "        \n",
    "        # Determine file type and read accordingly\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(('.xlsx', '.xls')):\n",
    "            df = pd.read_excel(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Please use CSV (.csv) or Excel (.xlsx, .xls) files.\")\n",
    "        \n",
    "        # Basic data info\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(\"\\nColumn names:\", df.columns.tolist())\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Check for missing values\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(df.isnull().sum())\n",
    "        \n",
    "        # Remove rows with missing text\n",
    "        df = df.dropna(subset=['text'])\n",
    "        \n",
    "        # Fill missing labels with 'unknown' or most frequent value\n",
    "        df['Emotion'] = df['Emotion'].fillna('neutral')\n",
    "        df['Offensive'] = df['Offensive'].fillna('no')\n",
    "        df['Hate'] = df['Hate'].fillna('not_hate')\n",
    "        \n",
    "        # Encode labels\n",
    "        df['emotion_encoded'] = self.emotion_encoder.fit_transform(df['Emotion'])\n",
    "        df['offensive_encoded'] = self.offensive_encoder.fit_transform(df['Offensive'])\n",
    "        df['hate_encoded'] = self.hate_encoder.fit_transform(df['Hate'])\n",
    "        \n",
    "        # Print label distributions\n",
    "        print(\"\\nLabel distributions:\")\n",
    "        print(\"Emotions:\", df['Emotion'].value_counts())\n",
    "        print(\"Offensive:\", df['Offensive'].value_counts())\n",
    "        print(\"Hate:\", df['Hate'].value_counts())\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_model(self, num_emotions, num_offensive, num_hate):\n",
    "        \"\"\"Create and initialize the multi-task model\"\"\"\n",
    "        print(\"Creating AraELECTRA model...\")\n",
    "        \n",
    "        model = MultiTaskAraELECTRA(\n",
    "            self.model_name,\n",
    "            num_emotions,\n",
    "            num_offensive,\n",
    "            num_hate\n",
    "        )\n",
    "        \n",
    "        model.to(self.device)\n",
    "        return model\n",
    "    \n",
    "    def train_model_full_data(self, model, train_loader, num_epochs=5, learning_rate=2e-5):\n",
    "        \"\"\"Train the multi-task model on full dataset without validation\"\"\"\n",
    "        print(\"Starting training on full dataset...\")\n",
    "        \n",
    "        # Loss functions for each task\n",
    "        criterion_emotion = nn.CrossEntropyLoss()\n",
    "        criterion_offensive = nn.CrossEntropyLoss()\n",
    "        criterion_hate = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Optimizer and scheduler\n",
    "        optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "        total_steps = len(train_loader) * num_epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        # Training history\n",
    "        train_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            \n",
    "            # Training phase\n",
    "            model.train()\n",
    "            total_train_loss = 0\n",
    "            \n",
    "            for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                emotion_labels = batch['emotion'].to(self.device)\n",
    "                offensive_labels = batch['offensive'].to(self.device)\n",
    "                hate_labels = batch['hate'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                emotion_logits, offensive_logits, hate_logits = model(input_ids, attention_mask)\n",
    "                \n",
    "                # Calculate losses\n",
    "                emotion_loss = criterion_emotion(emotion_logits, emotion_labels)\n",
    "                offensive_loss = criterion_offensive(offensive_logits, offensive_labels)\n",
    "                hate_loss = criterion_hate(hate_logits, hate_labels)\n",
    "                \n",
    "                # Combined loss (weighted sum)\n",
    "                total_loss = emotion_loss + offensive_loss + hate_loss\n",
    "                \n",
    "                # Backward pass\n",
    "                total_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                total_train_loss += total_loss.item()\n",
    "            \n",
    "            avg_train_loss = total_train_loss / len(train_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "            print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        return train_losses\n",
    "    \n",
    "    def predict_text(self, model, text):\n",
    "        \"\"\"Predict labels for a single text\"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            emotion_logits, offensive_logits, hate_logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Get predictions\n",
    "            emotion_pred = torch.argmax(emotion_logits, dim=1).item()\n",
    "            offensive_pred = torch.argmax(offensive_logits, dim=1).item()\n",
    "            hate_pred = torch.argmax(hate_logits, dim=1).item()\n",
    "            \n",
    "            # Get probabilities\n",
    "            emotion_probs = torch.softmax(emotion_logits, dim=1)[0]\n",
    "            offensive_probs = torch.softmax(offensive_logits, dim=1)[0]\n",
    "            hate_probs = torch.softmax(hate_logits, dim=1)[0]\n",
    "            \n",
    "            # Convert to original labels\n",
    "            emotion_label = self.emotion_encoder.inverse_transform([emotion_pred])[0]\n",
    "            offensive_label = self.offensive_encoder.inverse_transform([offensive_pred])[0]\n",
    "            hate_label = self.hate_encoder.inverse_transform([hate_pred])[0]\n",
    "            \n",
    "            return {\n",
    "                'emotion': {\n",
    "                    'label': emotion_label,\n",
    "                    'confidence': emotion_probs[emotion_pred].item()\n",
    "                },\n",
    "                'offensive': {\n",
    "                    'label': offensive_label,\n",
    "                    'confidence': offensive_probs[offensive_pred].item()\n",
    "                },\n",
    "                'hate': {\n",
    "                    'label': hate_label,\n",
    "                    'confidence': hate_probs[hate_pred].item()\n",
    "                }\n",
    "            }\n",
    "\n",
    "print(\"Main classifier class defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T15:33:13.261640Z",
     "iopub.status.busy": "2025-06-28T15:33:13.261356Z",
     "iopub.status.idle": "2025-06-28T15:33:13.268781Z",
     "shell.execute_reply": "2025-06-28T15:33:13.268114Z",
     "shell.execute_reply.started": "2025-06-28T15:33:13.261620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def train_arabic_classifier_full_data(data_file_path, num_epochs=3, batch_size=16, learning_rate=2e-5):\n",
    "    \"\"\"\n",
    "    Train the model using ALL training data without splitting\n",
    "    \n",
    "    Args:\n",
    "        data_file_path: Path to training data (CSV or Excel)\n",
    "        num_epochs: Number of training epochs\n",
    "        batch_size: Batch size for training\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    Returns:\n",
    "        classifier: Trained classifier object\n",
    "        model: Trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ARABIC MULTI-TASK TEXT CLASSIFICATION WITH ARAELECTRA\")\n",
    "    print(\"TRAINING ON FULL DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Initialize classifier with AraELECTRA\n",
    "    classifier = ArabicMultiTaskClassifier(\n",
    "        model_name='aubmindlab/araelectra-base-discriminator'\n",
    "    )\n",
    "    \n",
    "    # Load and prepare ALL training data\n",
    "    df = classifier.load_data(data_file_path)\n",
    "    \n",
    "    # Use ALL data for training (no train/val/test split)\n",
    "    train_dataset = ArabicTextDataset(\n",
    "        df['text'].values,\n",
    "        df['emotion_encoded'].values,\n",
    "        df['offensive_encoded'].values,\n",
    "        df['hate_encoded'].values,\n",
    "        classifier.tokenizer,\n",
    "        classifier.max_length\n",
    "    )\n",
    "    \n",
    "    # Create data loader for full training set\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Get number of classes for each task\n",
    "    num_emotions = len(classifier.emotion_encoder.classes_)\n",
    "    num_offensive = len(classifier.offensive_encoder.classes_)\n",
    "    num_hate = len(classifier.hate_encoder.classes_)\n",
    "    \n",
    "    print(f\"\\nTraining on {len(df)} samples\")\n",
    "    print(f\"Number of emotion classes: {num_emotions}\")\n",
    "    print(f\"Number of offensive classes: {num_offensive}\")\n",
    "    print(f\"Number of hate classes: {num_hate}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = classifier.create_model(num_emotions, num_offensive, num_hate)\n",
    "    \n",
    "    # Train model on full dataset\n",
    "    train_losses = classifier.train_model_full_data(\n",
    "        model, train_loader, num_epochs=num_epochs, learning_rate=learning_rate\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'aubmindlab/bert-base-arabertv2.pth')\n",
    "    print(\"\\nModel saved as 'aubmindlab/bert-base-arabertv2.pth'\")\n",
    "    \n",
    "    return classifier, model\n",
    "\n",
    "print(\"Training function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T15:33:51.772799Z",
     "iopub.status.busy": "2025-06-28T15:33:51.771791Z",
     "iopub.status.idle": "2025-06-28T15:33:51.783284Z",
     "shell.execute_reply": "2025-06-28T15:33:51.782645Z",
     "shell.execute_reply.started": "2025-06-28T15:33:51.772771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def predict_and_save_validation(classifier, model, validation_file_path, output_file_path=None):\n",
    "    \"\"\"\n",
    "    Make predictions on validation file and save results\n",
    "    \n",
    "    Args:\n",
    "        classifier: Trained classifier object\n",
    "        model: Trained model\n",
    "        validation_file_path: Path to validation CSV/Excel file\n",
    "        output_file_path: Path to save predictions (optional)\n",
    "    \n",
    "    Returns:\n",
    "        results_df: DataFrame with predictions\n",
    "    \"\"\"\n",
    "    print(f\"Loading validation file: {validation_file_path}\")\n",
    "    \n",
    "    # Load validation file\n",
    "    if validation_file_path.endswith('.csv'):\n",
    "        val_df = pd.read_csv(validation_file_path)\n",
    "    elif validation_file_path.endswith(('.xlsx', '.xls')):\n",
    "        val_df = pd.read_excel(validation_file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use CSV or Excel files.\")\n",
    "    \n",
    "    print(f\"Validation file loaded with {len(val_df)} samples\")\n",
    "    \n",
    "    # Check if 'text' column exists\n",
    "    if 'text' not in val_df.columns:\n",
    "        raise ValueError(\"Validation file must contain a 'text' column\")\n",
    "    \n",
    "    # Make predictions for all samples\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    \n",
    "    print(\"Making predictions on validation data...\")\n",
    "    for i, text in enumerate(tqdm(val_df['text'], desc=\"Predicting\")):\n",
    "        try:\n",
    "            prediction = classifier.predict_text(model, str(text))\n",
    "            all_predictions.append(prediction)\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting text at index {i}: {e}\")\n",
    "            # Add default prediction for failed cases\n",
    "            all_predictions.append({\n",
    "                'emotion': {'label': 'neutral', 'confidence': 0.0},\n",
    "                'offensive': {'label': 'no', 'confidence': 0.0},\n",
    "                'hate': {'label': 'not_hate', 'confidence': 0.0}\n",
    "            })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = val_df.copy()\n",
    "    results_df['emotion_predicted'] = [pred['emotion']['label'] for pred in all_predictions]\n",
    "    results_df['emotion_confidence'] = [pred['emotion']['confidence'] for pred in all_predictions]\n",
    "    results_df['offensive_predicted'] = [pred['offensive']['label'] for pred in all_predictions]\n",
    "    results_df['offensive_confidence'] = [pred['offensive']['confidence'] for pred in all_predictions]\n",
    "    results_df['hate_predicted'] = [pred['hate']['label'] for pred in all_predictions]\n",
    "    results_df['hate_confidence'] = [pred['hate']['confidence'] for pred in all_predictions]\n",
    "    \n",
    "    # Set output filename if not provided\n",
    "    if output_file_path is None:\n",
    "        output_file_path = f\"validation_predictions_{validation_file_path.split('/')[-1].split('.')[0]}.xlsx\"\n",
    "    \n",
    "    # Save predictions\n",
    "    results_df.to_excel(output_file_path, index=False)\n",
    "    print(f\"\\nPredictions saved to '{output_file_path}'\")\n",
    "    \n",
    "    # Show sample predictions\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAMPLE PREDICTIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i in range(min(5, len(results_df))):\n",
    "        row = results_df.iloc[i]\n",
    "        text = str(row['text'])\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
    "        print(f\"Predictions -> Emotion: {row['emotion_predicted']} (conf: {row['emotion_confidence']:.3f})\")\n",
    "        print(f\"              Offensive: {row['offensive_predicted']} (conf: {row['offensive_confidence']:.3f})\")\n",
    "        print(f\"              Hate: {row['hate_predicted']} (conf: {row['hate_confidence']:.3f})\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"Prediction function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T15:35:12.794155Z",
     "iopub.status.busy": "2025-06-28T15:35:12.793808Z",
     "iopub.status.idle": "2025-06-28T15:51:32.752263Z",
     "shell.execute_reply": "2025-06-28T15:51:32.751502Z",
     "shell.execute_reply.started": "2025-06-28T15:35:12.794133Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process...\n",
      "============================================================\n",
      "ARABIC MULTI-TASK TEXT CLASSIFICATION WITH ARAELECTRA\n",
      "TRAINING ON FULL DATASET\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96946fdf40d14cb0a5c19022c86ffa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23638d85eca48de8a0182ff1ec7cf71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fd3a5dd69c46049e6398d7e8db093c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319409e0cf3c4d3ea98d2b3bb0ceae00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1d683e265f42b299cfdf1219b22dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data...\n",
      "Dataset shape: (5960, 5)\n",
      "\n",
      "Column names: ['id', 'text', 'Emotion', 'Offensive', 'Hate']\n",
      "\n",
      "First few rows:\n",
      "     id                                               text       Emotion  \\\n",
      "0  2537  Ø£Ø­Ø¯ Ø§Ù„ØªØ¬Ø§Ø± Ø§Ù„Ø´Ø¨Ø§Ø¨ Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠÙŠÙ† ÙŠÙ‚ÙˆÙ„ Ù„Ù„Ø§Ø³Ù Ù„Ù…Ø§ ÙŠÙƒÙˆ...       neutral   \n",
      "1  5579  @JALHARBISKY Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø§Ù„Ù‚Ø¯Ø±Ø© Ø§Ù„Ø¬Ù†Ø³ÙŠÙ‡ğŸ‘<LF> <LF>Ø¨Ø¯...      optimism   \n",
      "2  6092        @rwn4o Ø­Ø¨ÙŠØ¨ÙŠÙŠÙŠ ÙˆØ§Ù„Ù„Ù‡ Ø§ÙƒØ«Ø«Ø«Ø±Ø± ÙŠØ§Ø±Ø¨ Ø§Ù…ÙŠÙ†ğŸ¥ºâ™¥ï¸â™¥ï¸          love   \n",
      "3  2540  #ÙˆØµØ§Ù„_Ø¯ÙˆØª_FM<LF>Ù…Ø¹ Ø³Ù…ÙŠØ±Ø© Ø§Ù„ÙØ·ÙŠØ³ÙŠØ© @Samira_Alfu...       neutral   \n",
      "4  3159  Ù…Ù† ÙŠÙ†ØªØ²Ø¹ Ø§Ø±ÙˆØ§Ø­ Ø§Ø·ÙØ§Ù„Ù†Ø§ Ù…Ù† Ø£Ø¬Ø³Ø§Ø¯Ù‡Ø§ Ø¨ÙƒÙ„ ÙˆØ­Ø´ÙŠØ© Ø¹Ù„...  anticipation   \n",
      "\n",
      "  Offensive Hate  \n",
      "0        no  NaN  \n",
      "1        no  NaN  \n",
      "2        no  NaN  \n",
      "3        no  NaN  \n",
      "4        no  NaN  \n",
      "\n",
      "Missing values:\n",
      "id              0\n",
      "text            0\n",
      "Emotion         0\n",
      "Offensive       0\n",
      "Hate         4216\n",
      "dtype: int64\n",
      "\n",
      "Label distributions:\n",
      "Emotions: Emotion\n",
      "anger           1551\n",
      "disgust          777\n",
      "neutral          661\n",
      "love             593\n",
      "joy              533\n",
      "anticipation     491\n",
      "optimism         419\n",
      "sadness          335\n",
      "confidence       210\n",
      "pessimism        194\n",
      "surprise         143\n",
      "fear              53\n",
      "Name: count, dtype: int64\n",
      "Offensive: Offensive\n",
      "no     4216\n",
      "yes    1744\n",
      "Name: count, dtype: int64\n",
      "Hate: Hate\n",
      "not_hate    5657\n",
      "hate         303\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training on 5960 samples\n",
      "Number of emotion classes: 12\n",
      "Number of offensive classes: 2\n",
      "Number of hate classes: 2\n",
      "Creating AraELECTRA model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88c5c3735b54af99e94cfa6d0ba236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on full dataset...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 373/373 [05:15<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 2.4768\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 373/373 [05:14<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.9411\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 373/373 [05:14<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.6898\n",
      "\n",
      "Model saved as 'arabic_multitask_araelectra_full_model.pth'\n",
      "\n",
      "Training completed successfully!\n",
      "\n",
      "Starting prediction process...\n",
      "Loading validation file: /kaggle/input/validation/validation.csv\n",
      "Validation file loaded with 1277 samples\n",
      "Making predictions on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1277/1277 [00:28<00:00, 44.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions saved to '/kaggle/working/validation_predictions_araelectra.xlsx'\n",
      "\n",
      "================================================================================\n",
      "SAMPLE PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Text: Ø§Ù„Ù†ÙŠÙˆÙƒ Ø¹Ù†Ø¯ÙŠ Ù…Ø«Ù„ Ø´Ø±Ø¨ Ø§Ù„ÙÙ†Ø§Ø¬ÙŠÙ„ #PS4share https://t.co/NgkLViK32J\n",
      "Predictions -> Emotion: neutral (conf: 0.752)\n",
      "              Offensive: no (conf: 0.904)\n",
      "              Hate: not_hate (conf: 0.980)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Text: Ù„Ù† Ø£ØªØ¹Ø§Ø·Ù Ù…Ø¹ Ù†Ø§Ø¯ÙŠ Ø¨Ø¹Ø¶ Ø¬Ù…Ù‡ÙˆØ±Ù‡ Ø§Ù„Ø·Ù‚Ø·Ù‚Ù‡ Ø¹Ù†Ø¯Ù‡ Ø´ØªÙ… Ùˆ Ù‚Ø°ÙÙˆØ§ ÙˆØ§Ù„Ø¯Ø© Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø²Ø§Ù‚ Ø­Ù…Ø¯Ø§Ù„Ù„Ù‡ ÙˆØ§Ø³Ø§Ø¡ÙˆØ§ Ù„Ù‡ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù„Ø¹Ø¨...\n",
      "Predictions -> Emotion: anger (conf: 0.594)\n",
      "              Offensive: yes (conf: 0.956)\n",
      "              Hate: not_hate (conf: 0.818)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Text: ÙŠØ§ Ø±Ø¨ÙŠ Ø§ÙŠÙ‡ Ø§Ù„Ø¸Ù„Ù… Ø¯Ù‡ğŸ˜¢<LF>Ø§Ù… Ù„Ø®Ù…Ø³ Ø§Ø·ÙØ§Ù„ ØªØ«ØªØºÙŠØ«<LF>Ù„ÙÙ‚ÙˆØ§ ØªÙ‡Ù… Ù„Ø²ÙˆØ¬Ù‡Ø§ Ø¹Ø´Ø§Ù† Ø±ÙØ¶ ÙŠØ´ØªØºÙ„ Ù…Ø¹Ø§Ù‡Ù… Ù…Ø±Ø´Ø¯<LF>ÙƒØ³Ø±ÙˆØ§ ...\n",
      "Predictions -> Emotion: anger (conf: 0.813)\n",
      "              Offensive: no (conf: 0.727)\n",
      "              Hate: not_hate (conf: 0.967)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Text: RT @4mm83: Ø§Ø¹Ù„Ø§Ù… Ø¹Ø§Ø± Ø®Ø§ÙŠÙ Ù…Ù† Ø§Ù„Ø¨Ù„Ø·Ø¬ÙŠ Ù…Ø±ØªØ¶ÙŠ #ÙØ§ÙŠÙ‚_ÙˆØ²Ø§Ù‡Ø±_Ø§Ø¹Ù„Ø§Ù…_Ø¹Ø§Ù‡Ø±\n",
      "Predictions -> Emotion: anger (conf: 0.486)\n",
      "              Offensive: yes (conf: 0.974)\n",
      "              Hate: not_hate (conf: 0.858)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Text: @puierq Ù‡Ùˆ Ø´ÙˆÙÙŠ Ø¹ Ø­Ø³Ø¨ Ø¨Ø³ Ø§Ù†Ø§ ÙƒØªØ¬Ø±Ø¨Ù‡ Ø­Ø¨ÙŠØª Ù…Ø±Ù‡ ÙˆÙ… ÙÙŠÙ‡ Ù…Ø¨Ø§Ø¯Ø±Ù‡ ÙˆÙƒØ±Ù‡Øª Ø§Ù„Ø­Ø¨ ÙˆØ¨Ø³ ÙˆØ§Ù„Ù„Ù‡\n",
      "Predictions -> Emotion: sadness (conf: 0.264)\n",
      "              Offensive: no (conf: 0.976)\n",
      "              Hate: not_hate (conf: 0.992)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "All processes completed successfully!\n",
      "Final predictions saved with 1277 samples\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train model on ALL training data\n",
    "print(\"Starting training process...\")\n",
    "classifier, model = train_arabic_classifier_full_data(\n",
    "    data_file_path='/kaggle/input/train44/train.csv',  # Your training file\n",
    "    num_epochs=3,\n",
    "    batch_size=16,\n",
    "    learning_rate=2e-5\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed successfully!\")\n",
    "\n",
    "# Step 2: Make predictions on validation file and save results\n",
    "print(\"\\nStarting prediction process...\")\n",
    "validation_results = predict_and_save_validation(\n",
    "    classifier=classifier,\n",
    "    model=model,\n",
    "    validation_file_path='/kaggle/input/validation/validation.csv',  # Your validation file\n",
    "    output_file_path='/kaggle/working/validation_predictions_araelectra.xlsx'  # Output file\n",
    ")\n",
    "\n",
    "print(\"\\nAll processes completed successfully!\")\n",
    "print(f\"Final predictions saved with {len(validation_results)} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7760713,
     "sourceId": 12312467,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7760906,
     "sourceId": 12312764,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
